---
title: "El mÃ­nimo absoluto que todo desarrollador de software debe de saber sobre Unicode en 2023 (Â¡Sigue sin haber excusas!)"
summary: "Modern extension to classic 2003 article by Joel Spolsky"
published: 2023-10-02
hackernews_id: 37735801
starred: true
---

_Translated from [English](../) by Juan Carlos PÃ©rez DomÃ­nguez._

Hace veinte aÃ±os, [Joel Spolsky escribiÃ³](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/):

> El texto plano no existe.
> No tiene sentido tener una cadena sin saber cÃ³mo estÃ¡ codificada. Ya no se puede seguir escondiendo la cabeza en el suelo y pretender que "plano" significa ASCII.

En veinte aÃ±os han cambiado muchas cosas. En 2003, la principal duda era: Â¿cÃ³mo estÃ¡ codificado esto?

En 2023, esa ya no es la cuestiÃ³n: hay un 98% de probabilidades de que estÃ© codificado en UTF-8. Â¡Por fin! Â¡Podemos esconder la cabeza en el suelo de nuevo!

../utf8_trend@2x.png

La cuestiÃ³n ahora es: Â¿cÃ³mo usar correctamente UTF-8 ? Â¡Veamos!

# Â¿Que es Unicode?

Unicode es un estÃ¡ndar que pretende unificar todos los lenguajes humanos, tanto pasados como actuales, y hacer que puedan usarse en los ordenadores.

En la prÃ¡ctica, Unicode es una tabla que asigna un nÃºmero Ãºnico a cada carÃ¡cter.

Por ejemplo:

- La letra `A` del alfabeto latino tiene asignado el nÃºmero `65`.
- La letra Seen `Ø³` del alfabeto Ã¡rabe es `1587`.
- La letra Tu `ãƒ„` del alfabeto Katakana es `12484`
- El sÃ­mbolo musical de clave de sol `ğ„` es `119070`.
- <code class="emoji">ğŸ’©</code> es `128169`.

Unicode llama a estos nÃºmeros _puntos de cÃ³digo_.

Como todo el mundo estÃ¡ de acuerdo en quÃ© nÃºmeros corresponden a cada carÃ¡cter y todos estamos de acuerdo en usar Unicode, todos podemos leer los textos de todos los demÃ¡s.

.loud Unicode == carÃ¡cter âŸ· punto de cÃ³digo.

# Â¿CÃ³mo de grande es Unicode?

Actualmente el punto de cÃ³digo mÃ¡s alto posible es el 0x10FFFF. Esto nos da un espacio de aproximadamente 1.1 millones de puntos de cÃ³digo.

Aproximadamente 170.000, o un 15%, estÃ¡n actualmente asignados a caracteres. Un 11% adicional estÃ¡n reservados para uso privado. El resto, unos 800.000 puntos de cÃ³digo no estÃ¡n todavÃ­a asignados. PodrÃ­an asociarse a nuevos caracteres en el futuro.

AsÃ­ es cÃ³mo se ve en lÃ­neas generales:

../overview@2x.png

Cuadrado grande == plano == 65.536 caracteres. Cuadrado pequeÃ±o == 256 caracteres. Todo ASCII cabe en la mitad del cuadrado pequeÃ±o rojo de la esquina superior izquierda.

# Â¿QuÃ© es el uso privado?

Corresponde a puntos de cÃ³digo reservados para desarrolladores de aplicaciones y nunca serÃ¡n asignados directamente por el propio Unicode.

Por ejemplo, no hay ningÃºn lugar para el logo de Apple en Unicode. Apple lo pone en `U+F8FF` que estÃ¡ en el bloque de uso privado. En cualquiera otra fuente se mostrarÃ¡ como glifo vacÃ­o `ô€£º`, pero en las fuentes que vienen con macOS, se verÃ¡ asÃ­: ![](../apple-logo@2x.png).

El Ã¡rea para uso privado se usa principalmente en fuentes de iconos:

../nerd_font@2x.png
Â¿No es una belleza? Â¡Todo es texto!

# Â¿QuÃ© significa `U+1F4A9`?

Es una convenciÃ³n para representar valores de puntos de cÃ³digo. El prefijo `U+` significa, bueno, Unicode, y `1F4A9` es un nÃºmero de punto de cÃ³digo en hexadecimal.

Oh, y `U+1F4A9` en particular es <code class="emoji">ğŸ’©</code>.

# Â¿QuÃ© es entonces UTF-8?

UTF-8 es una codificaciÃ³n. La codificaciÃ³n es la forma de almacenar los puntos de cÃ³digo en memoria.

La forma mÃ¡s sencilla de codificar Unicode es UTF-32. Simplemente se almacenan los puntos de cÃ³digo como enteros de 32 bits. AsÃ­ que `U+1F4A9` se convierte en `00 01 F4 A9`, ocupando cuatro bytes. Cualquier otro punto de cÃ³digo en UTF-32 tambiÃ©n ocuparÃ¡ cuatro bytes. Dado que el punto de cÃ³digo mÃ¡s alto definido es `U+10FFFF`, estÃ¡ garantizado que puede almacenarse cualquier punto de cÃ³digo.

UTF-16 y UTF-8 son menos directos pero el objetivo final es el mismo: tomar un punto de cÃ³digo y representarlo por una serie de bytes.

La codificaciÃ³n es con lo que realmente trabaja el programador.

# Â¿Cuantos bytes hay en UTF-8?

UTF-8 es una codificaciÃ³n de longitud variable. Un punto de cÃ³digo puede ser codificado por una secuencia de uno a cuatro bytes.

AsÃ­ es como funciona:

<table>
  <thead>
    <tr>
      <th>Punto de cÃ³digo</th>
      <th>Byte 1</th>
      <th>Byte 2</th>
      <th>Byte 3</th>
      <th>Byte 4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>U+<code>0000</code>..<code>007F</code></td>
      <td><code>0xxxxxxx</code></td>
    </tr>
    <tr>
      <td>U+<code>0080</code>..<code>07FF</code></td>
      <td><code>110xxxxx</code></td>
      <td><code>10xxxxxx</code></td>
    </tr>
    <tr>
      <td>U+<code>0800</code>..<code>FFFF</code></td>
      <td><code>1110xxxx</code></td>
      <td><code>10xxxxxx</code></td>
      <td><code>10xxxxxx</code></td>
    </tr>
    <tr>
      <td>U+<code>10000</code>..<code>10FFFF</code></td>
      <td><code>11110xxx</code></td>
      <td><code>10xxxxxx</code></td>
      <td><code>10xxxxxx</code></td>
      <td><code>10xxxxxx</code></td>
    </tr>
  </tbody>
</table>

Si se coteja esto con la tabla Unicode, se verÃ¡ que el inglÃ©s se codifica con un byte, los abecedarios de idiomas europeos como el cirÃ­lico, el latino, el hebreo y el Ã¡rabe necesitan dos bytes, y los de idiomas asiÃ¡ticos como el chino, japonÃ©s, coreano y los emojis necesitan tres o cuatro bytes.

Unas cuantas notas importantes aquÃ­:

Primero, UTF-8 es compatible con ASCII. Los puntos de cÃ³digo 0..127, el antiguo ASCII, se codifican con un byte, y con el mismo exacto byte. `U+0041` (`A`, Letra mayÃºscula latina A) es simplemente `41`, un byte.

Cualquier texto ASCII puro es tambiÃ©n un texto UTF-8 vÃ¡lido, y cualquier texto UTF-8 que solo use puntos de cÃ³digo 0..127 puede leerse directamente como ASCII.

Segundo, UTF-8 es eficiente en espacio para el alfabeto latino bÃ¡sico. Esa fue una de sus principales ventajas sobre UTF-16. Puede que no sea suficiente para textos de todo el mundo, pero para cadenas tÃ©cnicas como etiquetas HTML o claves JSON, tiene sentido.

En promedio, UTF-8 es una buena opciÃ³n, incluso para ordenadores que no son de habla inglesa. Y para inglÃ©s, no hay comparaciÃ³n.

Tercero, UTF-8 tiene detecciÃ³n y recuperaciÃ³n de errores incorporada. El prefijo de primer byte siempre es diferente de los bytes 2-4. De esta forma, siempre se puede saber si se estÃ¡ viendo una secuencia completa y vÃ¡lida de bytes UTF-8 o si falta algo (por ejemplo, por un salto al medio de una secuencia). Entonces se puede corregir el error moviÃ©ndose hacia adelante o hacia atrÃ¡s hasta encontrar el comienzo de la secuencia correcta.

Y algunas consecuencias importantes:

- NO SE PUEDE conocer la longitud de la cadena contando bytes.
- NO SE PUEDE saltar a un punto al azar de la cadena y comenzar a leer.
- NO SE PUEDE obtener una subcadena seleccionando un nÃºmero arbitrario de bytes. PodrÃ­a estarse eliminando parte de algÃºn carÃ¡cter.

Aquellos que lo hagan eventualmente se encontrarÃ¡n con este chico malo: ï¿½

# Â¿Que es ï¿½?

`U+FFFD`, el _carÃ¡cter de reemplazo_, es simplemente otro punto de cÃ³digo en la tabla de Unicode. Las aplicaciones y bibliotecas de software pueden usarlo cuando detectan errores Unicode.

Si se corta por la mitad un punto de cÃ³digo, no hay mucho que hacer con la otra mitad, excepto mostrar un error. Es entonces cuando se usa ï¿½.

```
var bytes = "ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°".getBytes("UTF-8");
var partial = Arrays.copyOfRange(bytes, 0, 11);
new String(partial, "UTF-8"); // => "ĞĞ½Ğ°Ğ»ï¿½"
```

# Â¿No serÃ­a mÃ¡s fÃ¡cil usar UTF-32 para todo?

NO.

UTF-32 es estupenda para operar con puntos de cÃ³digo. De hecho, si cada punto de cÃ³digo ocupa siempre 4 bytes, entonces `strlen(s) == sizeof(s) / 4`, `substring(0, 3) == bytes[0, 12]`, etc.

El problema es que no queremos operar con puntos de cÃ³digo. Un punto de cÃ³digo no es una unidad de escritura; un punto de cÃ³digo no siempre es un solo carÃ¡cter. Lo que se deberÃ­a iterar son las llamadas __agrupaciones extendidas de grafemas__, o simplemente grafemas.

Un grafema es una unidad mÃ­nima distintiva de escritura en un sistema de escritura particular. `Ã¶` es un grafema. `eÌ` tambiÃ©n lo es. Y `ê°`. BÃ¡sicamente, un grafema es lo que el usuario considera un carÃ¡cter simple.

El problema es que en Unicode, algunos grafemas estÃ¡n codificados con mÃºltiples puntos de cÃ³digo.

../graphemes@2x.png

Por ejemplo, `Ã¶` (un solo grafema) estÃ¡ codificado en Unicode como `o` (U+006F O MinÃºscula del alfabeto latino) + `Â¨` (U+0308 DiÃ©resis de combinaciÃ³n). Â¡Dos puntos de cÃ³digo!

TambiÃ©n pueden ser mÃ¡s de dos:

- <code class="emoji">â˜¹ï¸</code> es `U+2639` + `U+FE0F`
- <code class="emoji">ğŸ‘¨â€ğŸ­</code> es `U+1F468` + `U+200D` + `U+1F3ED`
- <code class="emoji">ğŸšµğŸ»â€â™€ï¸</code> es `U+1F6B5` + `U+1F3FB` + `U+200D` + `U+2640` + `U+FE0F`
- <code style="font-family: unset">yÌ–Ì ÍÌ˜Í‡Í—ÌÌ½ÌÍ</code> es `U+0079` + `U+0316` + `U+0320` + `U+034D` + `U+0318` + `U+0347` + `U+0357` + `U+030F` + `U+033D` + `U+030E` + `U+035E`

Hasta donde yo se, no hay lÃ­mite.

Recuerde que aquÃ­ estamos hablando de puntos de cÃ³digo. Incluso en la codificaciÃ³n mÃ¡s amplia, UTF-32, <code class="emoji">ğŸ‘¨â€ğŸ­</code> seguirÃ¡ ocupando tres unidades de 4 bytes y tendrÃ¡ que seguir siendo tratado como un solo carÃ¡cter.

Si una analogÃ­a ayuda, podemos pensar que Unicode mismo (sin codificaciones) es de longitud variable.

.loud Una agrupaciÃ³n de grafemas es una secuencia de uno o mÃ¡s puntos de cÃ³digo Unicode que deben ser tratados como un solo carÃ¡cter indivisible.

Por tanto, tenemos todos los problemas que tenemos con las codificaciones de longitud variable, pero ahora a nivel de puntos de cÃ³digo: no se puede tomar solo una parte de la secuencia, siempre debe seleccionarse, copiarse, editarse o eliminarse en su totalidad.

No respetar las agrupaciones de grafemas lleva a errores como este:

../error1.png

o este:

../intellij@2x.mp4
Solamente para que quede claro: este NO es el comportamiento correcto.

Utilizar UTF-32 no va a hacer que su vida sea mÃ¡s fÃ¡cil con las agrupaciones de grafemas. Y las agrupaciones de grafemas son lo que realmente deberÃ­a importarle.

.loud Puntos de cÃ³digo â€” ğŸ¥±. Grafemas â€” ğŸ˜

# Â¿Es difÃ­cil Unicode a causa solo de los emojis?

En realidad, no. Las agrupaciones de grafemas tambiÃ©n se utilizan para lenguajes vivos y activos. Por ejemplo:

- `Ã¶` (alemÃ¡n) es un solo carÃ¡cter, pero varios puntos de cÃ³digo (`U+006F U+0308`).
- `Ä…Ì` (lituano) es `U+00E1 U+0328`.
- `ê°` (koreano) es `U+1100 U+1161 U+11A8`.

Asi que no solamente es por los emojis.

# Â¿QuÃ© es "ğŸ¤¦ğŸ¼â€â™‚ï¸".length?

La pregunta estÃ¡ inspirada por [este brillante artÃ­culo](https://hsivonen.fi/string-length/).

Diferentes lenguajes de programaciÃ³n te darÃ¡n alegremente diferentes respuestas.

Python 3:

```
>>> len("ğŸ¤¦ğŸ¼â€â™‚ï¸")
5
```

JavaScript / Java / C#:

```
>>> "ğŸ¤¦ğŸ¼â€â™‚ï¸".length
7
```

Rust:

```
println!("{}", "ğŸ¤¦ğŸ¼â€â™‚ï¸".len());
// => 17
```

Como puede suponerse, diferentes lenguajes usan diferentes representaciones internas de cadenas (UTF-32, UTF-16, UTF-8) e informan de la longitud en las unidades que almacenan los caracteres (enteros, entero cortos, bytes).

Pero si le preguntas a cualquier persona normal, una que no estÃ© ofuscada con los entresijos de los ordenadores, te darÃ¡ una respuesta directa: 1. La longitud de la cadena <code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> es 1.

Esto es para lo que son las agrupaciones de grafemas: para lo que los humanos perciben como caracteres individuales. Y en este caso, <code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> es sin duda un solo carÃ¡cter.

El hecho de que <code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> consista en 5 puntos de cÃ³digo (`U+1F926 U+1F3FB U+200D U+2642 U+FE0F`) es un mero detalle de implementaciÃ³n. No deberÃ­a descomponerse, no deberÃ­a contarse como mÃºltiples caracteres, el cursor de texto no deberÃ­a posicionarse dentro de Ã©l, no deberÃ­a ser seleccionado parcialmente, etc.

Para todos los efectos, esto es una unidad atÃ³mica de texto. Internamente, podrÃ­a codificarse de cualquier manera, pero para la API orientada al usuario, deberÃ­a tratarse como un todo.

Los dos Ãºnicos lenguajes modernos que lo hacen bien son Swift:

```
print("ğŸ¤¦ğŸ¼â€â™‚ï¸".count)

// => 1
```

y Elixir:

```
String.length("ğŸ¤¦ğŸ¼â€â™‚ï¸")
// => 1
```

BÃ¡sicamente hay dos capas:

1. Interna, orientada a los ordenadores. Como copiar cadenas, enviarlas por la red, almacenarlas en disco, etc. AquÃ­ es donde se necesitan codificaciones como UTF-8. Swift usa UTF-8 internamente, pero podrÃ­a ser UTF-16 o UTF-32. Lo importante es que solo se use para copiar cadenas enteras y nunca para analizar su contenido.

2. Externa, orientada a los humanos. Como mostrar cadenas en la pantalla, como contar caracteres, como buscar en el texto, etc. MÃ©todos como `.count` or `.substring`. AquÃ­ es donde se necesitan las agrupaciones de grafemas. Swift te da una vista que presenta la cadena como una secuencia de clÃºsteres de grafemas. Y esa vista se comporta como cualquier humano esperarÃ­a: te da 1 para `"ğŸ¤¦ğŸ¼â€â™‚ï¸".count`.

Espero que pronto mÃ¡s lenguajes adopten este diseÃ±o.

Pregunta al lector: Â¿quÃ© cree que deberÃ­a ser <code style="font-family: unset">"áº‡Í“ÌÍ’ÍŸÍ¡Ç«Ì Ì Ì‰ÌÍ Í¡Í…rÌ¬ÌºÍšÌÍ›Ì”Í’Í¢dÌ ÍÌ—Ì³Í‡Í†Ì‹ÌŠÍ‚Í".length</code>?

# Entonces, Â¿cÃ³mo detectar las agrupaciones de grafemas?

Desafortunadamente, la mayorÃ­a de los lenguajes eligen la forma fÃ¡cil y te permiten iterar a travÃ©s de cadenas por trozos de 1-2-4 bytes, pero no por agrupaciones de grafemas.

No tiene sentido, pero como es el valor por defecto, los programadores no se lo piensan dos veces, y vemos cadenas corruptas como resultado:

../stdlib@2x.png

â€œVale, usarÃ© una biblioteca para hacer strlen()!â€ â€” dijo nadie, nunca.

Pero eso es exactamente lo que se deberÃ­a hacer. Â¡Hay que usar una biblioteca Unicode adecuada! Â¡SÃ­, para cosas bÃ¡sicas como `strlen` o `indexOf` o `substring`!

Por ejemplo:

1. C/C++/Java: usar [ICU](https://github.com/unicode-org/icu). Es una biblioteca de la propia Unicode que respeta todas las reglas sobre segmentaciÃ³n de texto.

2. C#: usar `TextElementEnumerator`, que se mantiene actualizado con Unicode hasta donde yo puedo decir.

3. Swift: simplemente `stdlib`. Swift lo hace bien por defecto.

4. UPD: Erlang/Elixir parece que lo hacen bien tambiÃ©n.

5. Para otros lenguajes, probablemente haya una biblioteca o adaptaciÃ³n de ICU.

6. HÃ¡galo Vd. mismo. Unicode [publica](https://www.unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries) reglas y tablas en formato legible por mÃ¡quina. Todas las bibliotecas anteriores se basan en ellas.

Pero, sea lo que sea que elija, asegÃºrese de que estÃ¡ en una versiÃ³n reciente de Unicode (15.1 en el momento de escribir esto), porque la definiciÃ³n de las agrupaciones de grafemas cambia de versiÃ³n a versiÃ³n. Por ejemplo, `java.text.BreakIterator` no debe de usarse ya: se basa en una versiÃ³n muy antigua de Unicode y no se actualiza.

.loud Utilice una biblioteca

En mi opiniÃ³n, todo el asunto es una vergÃ¼enza. Unicode deberÃ­a estar en la biblioteca estÃ¡ndar de todos los idiomas por defecto. Â¡Es la lengua franca de internet! Ni siquiera es nuevo: llevamos 20 aÃ±os conviviendo con Unicode.

# Un momento, Â¿estÃ¡n cambiando las reglas?

Si, Â¿no es genial?

(Lo sÃ©, no lo es)

Desde aproximadamente 2014, Unicode ha estado lanzando una revisiÃ³n importante de su estÃ¡ndar cada aÃ±o. De ahÃ­ es de donde salen los nuevos emojis: las actualizaciones de Android e iOS en otoÃ±o suelen incluir el estÃ¡ndar Unicode mÃ¡s reciente, entre otras cosas.

../versions@2x.png

Lo que es triste para nosotros es que las reglas que definen las agrupaciones de grafemas cambian cada aÃ±o tambiÃ©n. Lo que hoy se considera una secuencia de dos o tres puntos de cÃ³digo separados puede convertirse en una agrupaciÃ³n de grafemas maÃ±ana. Â¡No hay forma de saberlo! Â¡O de prepararse!

Â¡Peor aÃºn!, Â¡diferentes versiones de tu propia aplicaciÃ³n podrÃ­an estar ejecutÃ¡ndose en diferentes estÃ¡ndares Unicode y reportar diferentes longitudes de cadena!

Pero esta es la realidad en la que vivimos. Realmente no hay elecciÃ³n. No se pueden ignorar ni Unicode ni sus actualizaciones si se quiere seguir siendo relevante y proporcionar una experiencia de usuario decente. AsÃ­ que, Â¡a agarrarse los machos, aceptarlo y a actualizarse!

.loud Actualice cada aÃ±o

# Por quÃ© es "AÌŠ" !== "Ã…" !== "â„«"?

../spider_men@2x.jpg

Copie cualquiera de estos a la consola de JavaScript:

```
"AÌŠ" === "Ã…"
"Ã…" === "â„«"
"AÌŠ" === "â„«"
```

Â¿QuÃ© obtiene? Â¿False? DeberÃ­a obtener False. No es un error.

Recuerde cuando antes dije que `Ã¶` es dos puntos de cÃ³digo, `U+006F U+0308`? BÃ¡sicamente, Unicode ofrece mÃ¡s de una forma de escribir caracteres como `Ã¶` o `Ã…`. Puedes:

1. Componer `Ã…` a partir del carÃ¡cter `A` del alfabeto latino + un carÃ¡cter combinado,
2. O usar un carÃ¡cter pre-compuesto `U+00C5` que ya lo contiene.

Se verÃ¡n exactamente iguales (`AÌŠ` vs `Ã…`), funcionarÃ¡n igual, y para todos los efectos prÃ¡cticos, se consideran exactamente iguales. La Ãºnica diferencia es la representaciÃ³n interna en bytes.

Por eso necesitamos la normalizaciÃ³n. Hay cuatro formas:

**NFD** intenta separar todo en las piezas mÃ¡s pequeÃ±as posibles, y ordena las piezas en un orden canÃ³nico si hay mÃ¡s de una.

**NFC** por su parte intenta combinar todo en una forma pre-compuesta si existe.

../normalization@2x.png

Para algunos caracteres, hay mÃºltiples versiones de ellos en Unicode. Por ejemplo, hay una `U+00C5 Letra mayÃºscula A del alfabeto latino con un anillo encima`, pero tambiÃ©n hay un `U+212B SÃ­mbolo de Angstrom` que tiene el mismo aspecto.

Estos tambiÃ©n se reemplazan durante la normalizaciÃ³n:

../normalization_clones@2x.png

NFD y NFC se denominan â€œnormalizaciones canÃ³nicasâ€. Otras dos formas son â€œnormalizaciones de compatibilidadâ€:

**NFKD** intenta separar todo en las piezas mÃ¡s pequeÃ±as y reemplaza las variantes visuales con las predeterminadas.

**NFKC** intenta combinar todo mientras reemplaza las variantes visuales con las predeterminadas.

../normalization_compat@2x.png

Las variantes visuales son puntos de cÃ³digo Unicode separados que representan el mismo carÃ¡cter, pero se supone que se representan de distinta manera. Como, `â‘ ` o `â¹` o `ğ•`. Queremos poder encontrar tanto `"x"` y `"2"` en una cadena como `"ğ•Â²"`, Â¿no?

../x_variants@2x.png
Todas tienen sus puntos de cÃ³digo propios pero todas son equis.

Â¿PorquÃ© el sÃ­mbolo de ligadura `ï¬` tiene su propio punto de cÃ³digo? Ni idea. Pueden pasar muchas cosas en un millÃ³n de caracteres.

.loud Â¡Antes de comparar cadenas o buscar un subcadena, normalice!

# Unicode depende de la configuraciÃ³n regional

El nombre ruso Nikolay se escribe asÃ­:

../nikolay_ru.png

y se codifica en Unicode como: `U+041D 0438 043A 043E 043B 0430 0439`.

El nombre bÃºlgaro Nikolay se escribe asÃ­:

../nikolay_bg.png

y se codifica en Unicode como: `U+041D 0438 043A 043E 043B 0430 0439`. Â¡Exactamente lo mismo!

Â¡Un momento! Â¿CÃ³mo sabe el ordenador cuando representar los glifos al estilo bÃºlgaro y cuando al estilo ruso?

Respuesta corta: no lo sabe. Desafortunadamente, Unicode no es un sistema perfecto y tiene muchas deficiencias. Entre ellas estÃ¡ el hecho de asignar el mismo punto de cÃ³digo a glifos que deberÃ­an verse diferentes, como la letra K minÃºscula cirÃ­lica y la letra K minÃºscula bÃºlgara (ambas son `U+043A`).

SegÃºn tengo entendido, los asiÃ¡ticos [lo tienen mucho peor](https://en.wikipedia.org/wiki/Han_unification): muchos logogramas chinos, japoneses y coreanos que se escriben de forma muy diferente tienen el mismo punto de cÃ³digo en Unicode:

../han.png
U+8FD4 en diferentes configuraciones locales

La razÃ³n de Unicode para esto (creo) es ahorrar espacio de puntos de cÃ³digo. La informaciÃ³n sobre como representar se supone que debe de estar fuera de la cadena, en forma de metadatos de configuraciÃ³n regional/idioma.

Desafortunadamente, esto hace fallar uno de los objetivos originales de Unicode:

> [...] no se requerirÃ¡ ninguna secuencia de control para especificar ningÃºn carÃ¡cter de ningÃºn lenguaje.

En la prÃ¡ctica, la dependencia de la configuraciÃ³n regional trae muchos problemas:


1. Al ser metadatos, las configuraciones locales frecuentemente se pierden.

2. La gente no estÃ¡ limitada a una sola configuraciÃ³n regional. Por ejemplo, yo puedo leer y escribir en inglÃ©s (EE.UU.), inglÃ©s (Reino Unido), alemÃ¡n y ruso. Â¿QuÃ© configuraciÃ³n regional deberÃ­a establecer en mi ordenador?

3. Es difÃ­cil mezclar correctamente. Por ejemplo, nombres rusos en texto bÃºlgaro o viceversa. Â¿Pero por quÃ© no? Es internet, donde se reÃºne gente de todas las culturas.

4. No hay lugar para especificar la configuraciÃ³n regional. Incluso hacer las dos capturas de pantalla anteriores fue complicado porque en la mayorÃ­a del software no hay un menÃº desplegable o campo de texto para cambiar la configuraciÃ³n regional.

5. Cuando se necesita, tiene que adivinarse. Por ejemplo, Twitter intenta deducir la configuraciÃ³n regional del texto del tweet (porque, Â¿de dÃ³nde mÃ¡s podrÃ­a obtenerla?) y, claro, a veces se equivoca:

../twitter_locale.jpg https://twitter.com/nikitonsky/status/1171115067112398849

# Â¿Por quÃ© `String::toLowerCase()` acepta Locale (para la configuraciÃ³n regional) como argumento?

Otro desafortunado ejemplo de dependencia de la configuraciÃ³n regional es el manejo de Unicode de la letra `i` sin punto en el idioma turco.

A diferencia del inglÃ©s, los turcos tienen dos variantes de `I`: con punto y sin punto. Unicode decidiÃ³ reutilizar `I` e `i` de ASCII y solo aÃ±adir dos nuevos puntos de cÃ³digo: `Ä°` y `Ä±`.

Desafortunadamente, esto significa que `toLowerCase` y `toUpperCase` funcionan de forma diferente con la misma entrada:

```
var en_US = Locale.of("en", "US");
var tr = Locale.of("tr");

"I".toLowerCase(en_US); // =&gt; "i"
"I".toLowerCase(tr);    // =&gt; "Ä±"

"i".toUpperCase(en_US); // =&gt; "I"
"i".toUpperCase(tr);    // =&gt; "Ä°"
```

AsÃ­ que no, no puedes convertir una cadena a minÃºsculas sin saber en quÃ© idioma estÃ¡ escrita esa cadena.

# Yo vivo en EE.UU./Reino Unido, Â¿deberÃ­a importarme todo esto?

../english@2x.png
Incluso el inglÃ©s puro utiliza muchos caracteres tipogrÃ¡ficos que no estÃ¡n en ASCII.

- comillas `â€œ` `â€` `â€˜` `â€™`,
- apÃ³strofos `â€™`,
- barras `â€“` `â€”`,
- diferentes variantes de espacios (entre cifras, de ajuste fino, irrompible),
- marcas de lista `â€¢` `â– ` `â˜`,
- sÃ­mbolos de moneda distintos de `$``â‚¬` `Â¢` `Â£`,
- los signos de suma `+` y de igual `=` estÃ¡n en ASCII, pero el de resta `âˆ’` y multiplicaciÃ³n `Ã—` no <nobr>Â¯\_(ãƒ„)_/Â¯</nobr>,
- varios otros sÃ­mbolos `Â©` `â„¢` `Â¶` `â€ ` `Â§`.

Vaya, ni siquiera puedes escribir correctamente `cafÃ©`, `piÃ±ata`, or `naÃ¯ve` sin Unicode. AsÃ­ que si, estamos todos en esto, incluso los americanos.

TouchÃ©.

# Â¿Que son los pares subrogados?

Esto se remonta al Unicode v1. La primera versiÃ³n de Unicode se suponÃ­a que serÃ­a de ancho fijo. Un ancho fijo de 16 bits, para ser exactos:

../unicode1@2x.png
VersiÃ³n 1.0 del estÃ¡ndar Unicode, octubre de 1991

Pensaban que 65.536 caracteres serÃ­an suficientes para todos los lenguajes humanos. Â¡Casi aciertan!

Cuando se dieron cuenta de que necesitaban mÃ¡s puntos de cÃ³digo, UCS-2 (una versiÃ³n original de UTF-16 sin subrogados) ya estaba siendo utilizada en muchos sistemas. Un ancho fijo de 16 bits, solamente da para 65.536 caracteres. Â¿QuÃ© se podÃ­a hacer?

Unicode decidiÃ³ asignar algunos de estos 65.536 caracteres para codificar puntos de cÃ³digo mÃ¡s altos, convirtiendo esencialmente UCS-2 de ancho fijo en UTF-16 de ancho variable.

Un par subrogado se forma de dos unidades UTF-16 para codificar un Ãºnico punto de cÃ³digo Unicode. Por ejemplo, `D83D DCA9` (dos unidades de 16 bits) codifica _un_ punto de cÃ³digo, `U+1F4A9`.

Los 6 bits mÃ¡s altos de un par subrogado se utilizan para la mÃ¡scara, dejando 2Ã—10 bits libres:

```
Alto del Subrogado     Bajo del subrogado
       D800         ++        DC00
1101 10?? ???? ???? ++ 1101 11?? ???? ????
```

TÃ©cnicamente, las dos mitades del par subrogado tambiÃ©n pueden verse como puntos de cÃ³digo Unicode. En la prÃ¡ctica, todo el rango de `U+D800` a `U+DFFF` estÃ¡ reservado "exclusivamente para pares subrogados". Los puntos de cÃ³digo de esa parte no se consideran vÃ¡lidos en ninguna otra codificaciÃ³n.

../bmp@2x.png
Este espacio del muy abarrotado Plano MultilingÃ¼e BÃ¡sico nunca se utilizarÃ¡ jamÃ¡s serÃ¡ para nada bueno.

# Â¿EstÃ¡ aÃºn vivo UTF-16?

Â¡Si!

La promesa de una codificaciÃ³n de ancho fijo que cubriera todos los lenguajes humanos era tan atractiva que muchos sistemas estaban deseosos de adoptarla. Entre ellos estaban Microsoft Windows, Objective-C, Java, JavaScript, .NET, Python 2, QT, SMS, Â¡incluso CD-ROM!

Desde entonces, Python ha evolucionado, el CD-ROM estÃ¡ obsoleto, pero el resto se ha quedado estancado en UTF-16 o incluso UCS-2. Por lo tanto, UTF-16 sigue usÃ¡ndose para la representaciÃ³n en memoria.

En tÃ©rminos prÃ¡cticos, UTF-16 es tan usable como UTF-8. TambiÃ©n es de longitud variable; contar unidades UTF-16 es tan inÃºtil como contar bytes o puntos de cÃ³digo, las agrupaciones de grafemas siguen siendo un dolor de cabeza, etc. La Ãºnica diferencia son los requisitos de memoria.

La Ãºnica desventaja de UTF-16 es que todo lo demÃ¡s estÃ¡ en UTF-8, por lo que requiere conversiÃ³n cada vez que se lee una cadena desde la red o desde el disco.

Y, dato curioso: el nÃºmero de planos que tiene Unicode (17) estÃ¡ definido por cuÃ¡nto se puede expresar con pares subrogados en UTF-16.

# ConclusiÃ³n

Resumiendo:

- Unicode ha ganado.
- UTF-8 es la codificaciÃ³n mÃ¡s popular para datos en movimiento y en reposo.
- UTF-16 se utiliza aÃºn algunas veces para la representaciÃ³n en memoria.
- Las dos formas mÃ¡s importantes de ver las cadanas son como una secuencia de bytes (para asignar memoria, copiar, decodificar) y las agrupaciones de grafemas (para todas las operaciones semÃ¡nticas).
- Utilizar puntos de cÃ³digo para iterar sobre una cadena es incorrecto. No son la unidad bÃ¡sica de escritura. Un solo grafema puede consistir en mÃºltiples puntos de cÃ³digo.
- Para detectar agrupaciones de grafemas, se necesitan las tablas de Unicode.
- Utilice una biblioteca Unicode para todo lo relacionado con Unicode, incluso para cosas aburridas como `strlen`, `indexOf` y `substring`.
- Unicode se actualiza cada aÃ±o y algunas veces las reglas cambian.
- Las cadenas Unicode deben de normalizarse antes de poder ser comparadas.
- Unicode depende de la configuraciÃ³n regional para algunas operaciones y para la presentaciÃ³n.
- Todo esto es importante incluso para texto en inglÃ©s puro.

En resumen, Unicode no es perfecto pero el hecho de que

1. exista un cÃ³digo que cubre todos los lenguajes posibles a la vez,
2. todo el mundo estÃ© de acuerdo en usarlo,
3. podamos olvidarnos completamente de codificaciones y conversiones y de todas esas cosas

es un milagro. EnvÃ­e esto a sus compaÃ±eros programadores para que puedan aprender sobre ello tambiÃ©n.

.loud Si que existe el texto plano, y estÃ¡ codificado con UTF-8.

Gracias a Lev Walkin y a mis patrocinadores por leer los primeros borradores de este artÃ­culo.
